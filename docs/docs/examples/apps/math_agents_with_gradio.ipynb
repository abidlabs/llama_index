{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Basic Math Agent\n",
    "\n",
    "This chatbot allows users to ask basic math questions and get answers -- its like an LLM that knows how to use a calculator. This example is very simplistic but it shows you could build more sophisticated agents using Llama Index and visualize them with Gradio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers and returns the product\"\"\"\n",
    "    return a * b\n",
    "\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
    "\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers and returns the sum\"\"\"\n",
    "    return a + b\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "\n",
    "def subtract(a: float, b: float) -> float:\n",
    "    \"\"\"Subtract two numbers and returns the difference\"\"\"\n",
    "    return a - b\n",
    "\n",
    "subtract_tool = FunctionTool.from_defaults(fn=subtract)\n",
    "\n",
    "def divide(a: float, b: float) -> float:\n",
    "    \"\"\"Divide two numbers and returns the quotient\"\"\"\n",
    "    return a / b\n",
    "\n",
    "divide_tool = FunctionTool.from_defaults(fn=divide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Generator\n",
    "from io import StringIO\n",
    "import sys\n",
    "import threading\n",
    "import queue\n",
    "import time\n",
    "import re\n",
    "from gradio import ChatMessage\n",
    "\n",
    "def get_math_response(question: str, history) -> Generator[list[ChatMessage], None, None]:\n",
    "    output_queue = queue.Queue()\n",
    "    \n",
    "    class QueuedStringIO(StringIO):\n",
    "        def write(self, txt):\n",
    "            if txt.strip():\n",
    "                output_queue.put(txt)\n",
    "            return super().write(txt)\n",
    "    \n",
    "    string_buffer = QueuedStringIO()\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = string_buffer\n",
    "    \n",
    "    try:\n",
    "        def run_agent():\n",
    "            llm = OpenAI(model=\"gpt-4\", temperature=0)\n",
    "            agent = ReActAgent.from_tools(\n",
    "                [multiply_tool, add_tool, subtract_tool, divide_tool], \n",
    "                llm=llm, \n",
    "                verbose=True\n",
    "            )\n",
    "            response = agent.chat(question)\n",
    "            output_queue.put(f\"Final answer: {str(response)}\")\n",
    "            output_queue.put(None)\n",
    "        \n",
    "        thread = threading.Thread(target=run_agent)\n",
    "        thread.start()\n",
    "        \n",
    "        messages = []\n",
    "        # Regex patterns\n",
    "        thought_pattern = r\"Thought: (.*?)(?=Action:|Answer:|$)\"\n",
    "        action_pattern = r\"Action: (\\w+)\\nAction Input: ({.*?})\"\n",
    "        observation_pattern = r\"Observation: (.*?)(?=\\[|$)\"\n",
    "        answer_pattern = r\"Answer: (.*?)(?=\\[|$)\"\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                line = output_queue.get(timeout=0.1)\n",
    "                if line is None:\n",
    "                    break\n",
    "                    \n",
    "                # Match thought\n",
    "                thought_match = re.search(thought_pattern, line, re.DOTALL)\n",
    "                if thought_match:\n",
    "                    thought = thought_match.group(1).strip()\n",
    "                    messages.append(ChatMessage(\n",
    "                        metadata={\"title\": \"Thought\"},\n",
    "                        content=thought\n",
    "                    ))\n",
    "                    yield messages\n",
    "                \n",
    "                # Match action and observation\n",
    "                action_match = re.search(action_pattern, line, re.DOTALL)\n",
    "                obs_match = re.search(observation_pattern, line)\n",
    "                if action_match and obs_match:\n",
    "                    action = action_match.group(1)\n",
    "                    action_input = action_match.group(2)\n",
    "                    observation = obs_match.group(1).strip()\n",
    "                    messages.append(ChatMessage(\n",
    "                        metadata={\"title\": f\"Action: {action} {action_input}\"},\n",
    "                        content=f\"Observation: {observation}\"\n",
    "                    ))\n",
    "                    yield messages\n",
    "                \n",
    "                # Match answer\n",
    "                answer_match = re.search(answer_pattern, line)\n",
    "                if answer_match:\n",
    "                    answer = answer_match.group(1).strip()\n",
    "                    messages.append(ChatMessage(\n",
    "                        content=f\"Answer: {answer}\"\n",
    "                    ))\n",
    "                    yield messages\n",
    "                \n",
    "            except queue.Empty:\n",
    "                continue\n",
    "            \n",
    "    finally:\n",
    "        sys.stdout = old_stdout\n",
    "        string_buffer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7878\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.ChatInterface(get_math_response, type=\"messages\", chatbot=gr.Chatbot(type=\"messages\")).launch(inline=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Final answer: The result of the expression 20+(2*4) is 28.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
